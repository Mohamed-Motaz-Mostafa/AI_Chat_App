{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".Yellow{color: Yellow;}\n",
    ".Black{color: Black;}\n",
    ".custom-style {\n",
    "    color: Maroon;\n",
    "    font-family: sans-serif;\n",
    "    font-size: 150px;\n",
    "    text-align: center;\n",
    "    margin-top: 5px;\n",
    "    margin-bottom: 5px;\n",
    "}\n",
    "</style>\n",
    "<p class=\"custom-style\">\n",
    "<span class=Black>De</span><span class=Yellow>X</span><span class=Black>alo</span>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this project, I will develop a simple RAG (Retrieval-Augmented Generation) powered by OpenAI model with LangChain. and a calculator tool.\n",
    "\n",
    "## `This Notebook is only to test the tools used in the project.`\n",
    "# Key Requirements\n",
    "- The application should be able to answer questions about the content of a PDF/txt file.\n",
    "- The application should be able to perform calculations using a calculator tool.\n",
    "- The application should be able to handle multiple files and provide answers based on the content of the files.\n",
    "- A FastAPI backend\n",
    "- A React frontend\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "Any necessary libraries are imported in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import Type\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import tempfile\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definition & Global Variables\n",
    "The functions & global or enviroment variables that will be used in the notebook are defined in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple calculator tool that our agent can use\n",
    "class CalculatorInput(BaseModel):\n",
    "    expression: str = Field(description=\"Mathematical expression to evaluate\")\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name: str = \"calculator\"\n",
    "    description: str = \"Useful for performing mathematical calculations\"\n",
    "    args_schema: Type[BaseModel] = CalculatorInput\n",
    "    \n",
    "    def _run(self, expression: str) -> str:\n",
    "        \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "        try:\n",
    "            # Add basic math functions to the locals\n",
    "            local_dict = {\n",
    "                'sqrt': math.sqrt,\n",
    "                'pow': pow,\n",
    "                'abs': abs,\n",
    "                'round': round,\n",
    "                'max': max,\n",
    "                'min': min,\n",
    "                'sin': math.sin,\n",
    "                'cos': math.cos,\n",
    "                'tan': math.tan,\n",
    "                'pi': math.pi,\n",
    "                'e': math.e,\n",
    "                'log': math.log,\n",
    "                'log10': math.log10,\n",
    "                'floor': math.floor,\n",
    "                'ceil': math.ceil\n",
    "            }\n",
    "            \n",
    "            # Evaluate the expression\n",
    "            result = eval(expression, {\"__builtins__\": {}}, local_dict)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Error evaluating expression: {str(e)}\"\n",
    "\n",
    "    async def _arun(self, expression: str) -> str:\n",
    "        \"\"\"Async version of _run.\"\"\"\n",
    "        return self._run(expression)\n",
    "    \n",
    "\n",
    "\n",
    "def test_agent(query , agent):\n",
    "    print(f\"\\n--- Testing: '{query}' ---\")\n",
    "    response = agent.invoke(input=query)\n",
    "    print(f\"\\nFinal response: {response['output']}\")\n",
    "    print(\"-----------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Define a simple function to simulate RAG context\n",
    "def query_with_context(query, context , agent):\n",
    "    \"\"\"Simulate a query with RAG context\"\"\"\n",
    "    enriched_query = (\n",
    "        f\"I have a question that may require information from these documents:\\n\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        f\"My question is: {query}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Testing with RAG context ---\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Using context: '{context[:100]}...'\")\n",
    "    \n",
    "    response = agent.invoke(input=enriched_query)\n",
    "    \n",
    "    print(f\"\\nFinal response: {response['output']}\")\n",
    "    print(\"-----------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "This section demonstrates how LangChain agents work with tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\") # start by using the gpt-3.5-turbo model then switch to gpt-4 if needed or after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# test with simple prompt\n",
    "answer = llm.invoke(\"What is the capital of France?\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create memory to store chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CalculatorTool()]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,  # This shows the agent's thought process\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the agent with different types of queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing: 'What is the square root of 144 plus 5?' ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"calculator\",\n",
      "    \"action_input\": \"sqrt(144) + 5\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m17.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"17.0\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: 17.0\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_agent(\"What is the square root of 144 plus 5?\", agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing: 'Tell me about the weather today' ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I'm an AI assistant and do not have real-time information. You can check the weather using a weather website or app for the most up-to-date information.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: I'm an AI assistant and do not have real-time information. You can check the weather using a weather website or app for the most up-to-date information.\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_agent(\"Tell me about the weather today\" , agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing: 'If I have 3 apples and each costs $2.50, and I also buy 2 oranges at $1.75 each, how much will I spend in total?' ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"calculator\",\n",
      "    \"action_input\": \"3 * 2.50 + 2 * 1.75\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m11.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"11.0\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: 11.0\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_agent(\"If I have 3 apples and each costs $2.50, and I also buy 2 oranges at $1.75 each, how much will I spend in total?\" , agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with RAG context ---\n",
      "Query: 'What was my graduation project?'\n",
      "Using context: 'Projects: \n",
      " Wireless Chess Robotic Arm (WCRA-AI)  Graduation Project. Grade: Excellent.  \n",
      "▪ Designe...'\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Wireless Chess Robotic Arm (WCRA-AI) Graduation Project. Grade: Excellent. Designed & built a chess-playing robotic arm utilizing CNN and IoT with two operation modes. Implemented strategic decision-making using the NegaMax search algorithm on a Raspberry Pi. Guide search algorithm with efficiently updatable neural network (NNUE) as evaluation function. Integrated computer vision for gameplay & data collection to train CNN. Kaggle\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: Wireless Chess Robotic Arm (WCRA-AI) Graduation Project. Grade: Excellent. Designed & built a chess-playing robotic arm utilizing CNN and IoT with two operation modes. Implemented strategic decision-making using the NegaMax search algorithm on a Raspberry Pi. Guide search algorithm with efficiently updatable neural network (NNUE) as evaluation function. Integrated computer vision for gameplay & data collection to train CNN. Kaggle\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample context that simulates retrieved document chunks from my CV\n",
    "sample_context = \"\"\"Projects: \n",
    " Wireless Chess Robotic Arm (WCRA-AI)  Graduation Project. Grade: Excellent.  \n",
    "▪ Designed & built a chess-playing robotic arm utilizing CNN and IoT with two operation modes. \n",
    "▪ Implemented strategic decision-making using the NegaMax search algorithm on a Raspberry Pi. \n",
    "▪ Guide search algorithm with efficiently updatable neural network (NNUE) as evaluation function. \n",
    "▪ Integrated computer vision for gameplay & data collection to train CNN. Kaggle \n",
    " AI Model Testing & Reporting (NLP  Computer Vision) (Individual) \n",
    "▪ Extracted CAMeLBERT sentiment analysis strengths, drawbacks & potential use cases in a report. \n",
    "▪ Extracted FaceNet512 strengths & drawbacks through challenging selective examples in a report. \n",
    " Quantity Forecasting Across Different Products & Cities (Time Series) (Individual). \n",
    "▪ Data exploration, visualization, preprocessing & feature engineering. \n",
    "▪ Time series cross-validation Modeling (Exponential smoothing, ARIMA, Prophet, & LSTM). \n",
    "▪ Tailor a new zero-aware error metric to suit the problem & squeeze performance using N-BEATS. \n",
    " Enhanced Valuation of Personal Injury Claims (Omdena Project) Demo. \n",
    "▪ Collaborated with an international team to develop a predictive model for injury claims. \n",
    "▪ Data collection, analysis, visualization, and preprocessing. \n",
    "▪ Applied machine learning techniques to improve transparency and accuracy in legal processes. \n",
    " AI Research Assistant (CrewAI) (individual). \n",
    "▪ Multi-agent AI system to help researchers identify trends and research gaps. \n",
    "▪ 3 specialized AI agents to conduct comprehensive research & a user-friendly Streamlit app. \n",
    "▪ Utilize APIs to access the latest research papers and tech news to guide the next research steps. \n",
    "\"\"\"\n",
    "\n",
    "# Test with context\n",
    "query_with_context(\"What was my graduation project?\", sample_context , agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG (Retrieval-Augmented Generation) System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split document into 8 chunks\n",
      "\n",
      "Sample chunks:\n",
      "\n",
      "Chunk 1:\n",
      "Content: Mohamed Moataz \n",
      "Phone: (+20) 1120682864             \n",
      "Email:  mohamad.motaz.mostafa@gmail.com        ...\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 2:\n",
      "Content:  Diploma - Information Technology Institute (ITI)  \n",
      "- Supervised by the Ministry of Communication to...\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 3:\n",
      "Content: -playing robotic arm utilizing CNN and IoT with two operation modes. \n",
      "▪ Implemented strategic decisi...\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 4:\n",
      "Content:  Different Products & Cities (Time Series) (Individual).  \n",
      "▪ Data exploration, visualization, prepro...\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 5:\n",
      "Content:  in legal processes. \n",
      " AI Research Assistant (CrewAI) (individual).  \n",
      "▪ Multi-agent AI system to he...\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Token Text Splitter for chunking\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=200,  # Smaller chunks for demonstration\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# 4. Load and split the document\n",
    "loader = PyPDFLoader(\"Mohamed Motaz CV.pdf\")\n",
    "documents = loader.load()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split document into {len(chunks)} chunks\")\n",
    "print(\"\\nSample chunks:\")\n",
    "for i, chunk in enumerate(chunks[:5]):  # Show first 3 chunks\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"Content: {chunk.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {chunk.metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split document into 5 chunks\n",
      "\n",
      "Sample chunks:\n",
      "\n",
      "Chunk 1:\n",
      "Content: Mohamed Moataz \n",
      "Phone: (+20) 1120682864             \n",
      "Email:  mohamad.motaz.mostafa@gmail.com             \n",
      "LinkedIn: mohamed-moataz \n",
      "Military Status: Completed. Professional Summary:  \n",
      "Data Scientist with a strong foundation in mathematics and experience in developing and deploying AI \n",
      "models....\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 2:\n",
      "Content: Proven abilities in data exploration, machine learning, and software development. Passionate \n",
      "about advancing AI & ML technologies, scientific research, and contributing to innovative projects. Education: \n",
      "AI & ML 9-month Diploma - Information Technology Institute (ITI)  \n",
      "- Supervised by the Ministry of Communication to learn AI and ML through practical projects. Bachelor of Engineering in Computer & Communication Engineering (2017)  GPA: 3.05 \n",
      "Work Experience & Internships: \n",
      "Freelancer – Upwork  \n",
      "AI Developer – SWIFT ACT  \n",
      "- Design and develop a local RAG system (Chatbot) using Llama 3. - Design and develop an Exam Grading tool. Projects: \n",
      " Wireless Chess Robotic Arm (WCRA-AI) – Graduation Project. Grade: Excellent. ▪ Designed & built a chess-playing robotic arm utilizing CNN and IoT with two operation modes. ▪ Implemented strategic decision-making using the NegaMax search algorithm on a Raspberry Pi. ▪ Guide search algorithm with efficiently updatable neural network (NNUE) as evaluation function. ▪ Integrated computer vision for gameplay & data collection to train CNN. Kaggle \n",
      " AI Model Testing & Reporting (NLP – Computer Vision) (Individual)  \n",
      "▪ Extracted CAMeLBERT sentiment analysis strengths, drawbacks & potential use cases in a report. ▪ Extracted FaceNet512 strengths & drawbacks through challenging selective examples in a report.  Quantity Forecasting Across Different Products & Cities (Time Series) (Individual)....\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 3:\n",
      "Content: ▪ Data exploration, visualization, preprocessing & feature engineering. ▪ Time series cross-validation Modeling (Exponential smoothing, ARIMA, Prophet, & LSTM). ▪ Tailor a new zero-aware error metric to suit the problem & squeeze performance using N-BEATS.  Enhanced Valuation of Personal Injury Claims (Omdena Project) Demo. ▪ Collaborated with an international team to develop a predictive model for injury claims. ▪ Data collection, analysis, visualization, and preprocessing. ▪ Applied machine learning techniques to improve transparency and accuracy in legal processes.  AI Research Assistant (CrewAI) (individual). ▪ Multi-agent AI system to help researchers identify trends and research gaps. ▪ 3 specialized AI agents to conduct comprehensive research & a user-friendly Streamlit app. ▪ Utilize APIs to access the latest research papers and tech news to guide the next research steps.  Credit Card Data Clustering (Unsupervised Machine Learning) (Individual). ▪ Data Preprocessing & Investigation. ▪ Apply Clustering Algorithms: K-Means, Hierarchical Clustering, DBSCAN. ▪ Apply PCA and Kernel PCA, and Visualization using t-SNE. Technical Skills: \n",
      " Programming Languages: Python, C, C++, MATLAB, SQL, NoSQL.  Machine & Deep Learning: Scikit-Learn, TensorFlow, Keras, PyTorch, OpenCV, CrewAI.  Data Analysis & Visualization: Pandas, NumPy, PySpark, Plotly, Matplotlib, Seaborn.  Software Engineering: Strong background in OOP, data structures, algorithms, Linux, and CI/CD....\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 4:\n",
      "Content: All certifications are available upon request. GitHub \n",
      "Hackathons: \n",
      "Q-tech & ITI Hackathon \n",
      "Ranked 3rd place among 15 different teams from ITI graduation projects. Certificate  \n",
      "Certifications\n",
      " Intermediate Machine Learning, Kaggle....\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}\n",
      "\n",
      "Chunk 5:\n",
      "Content:  Data Analysis Challenger, Udacity.  AI & Problem-solving, IEEE-MYT.  Multi AI Agent Systems with CrewAI, deeplearning.ai.  Azure AI fundamentals, Microsoft.  AWS Cloud Foundations, AWS Academy.  CCNA v7, NTI. Volunteering Work: \n",
      "Student Union  \n",
      "▪ Orphan's Day party - Organizer. ▪ Feek El-kheer, Ramadan. ▪ Newcomer’s Day - Organizer. ▪ Organizing Nursing home visits. Dream Family Student Activity \n",
      "▪ Head of Science Committee. ▪ Social media coverage specialist. ▪ Trip Organizer. ▪ Dream Family Ledar....\n",
      "Metadata: {'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Token Text Splitter for chunking\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "\n",
    "# 4. Load and split the document\n",
    "loader = PyPDFLoader(\"Mohamed Motaz CV.pdf\")\n",
    "documents = loader.load()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split document into {len(chunks)} chunks\")\n",
    "print(\"\\nSample chunks:\")\n",
    "for i, chunk in enumerate(chunks[:5]):  # Show first 3 chunks\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"Content: {chunk.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {chunk.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings and vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query: str, k: int = 3):\n",
    "    \"\"\"Search for relevant document chunks.\"\"\"\n",
    "    print(f\"\\n--- Searching for: '{query}' ---\")\n",
    "    results = vector_store.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"Found {len(results)} relevant chunks:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"\\nResult {i+1}:\")\n",
    "        print(f\"Content: {doc.page_content}\")\n",
    "        print(f\"Similarity: Present in top {k} results\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Searching for: 'What is my email addres?' ---\n",
      "Found 1 relevant chunks:\n",
      "\n",
      "Result 1:\n",
      "Content: Mohamed Moataz \n",
      "Phone: (+20) 1120682864             \n",
      "Email:  mohamad.motaz.mostafa@gmail.com             \n",
      "LinkedIn: mohamed-moataz \n",
      "Military Status: Completed. Professional Summary:  \n",
      "Data Scientist with a strong foundation in mathematics and experience in developing and deploying AI \n",
      "models.\n",
      "Similarity: Present in top 1 results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='7d203892-c789-4395-8f5e-253473905564', metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-04-10T19:58:19+02:00', 'author': 'Win 10', 'moddate': '2025-04-10T19:58:19+02:00', 'source': 'Mohamed Motaz CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Mohamed Moataz \\nPhone: (+20) 1120682864             \\nEmail:  mohamad.motaz.mostafa@gmail.com             \\nLinkedIn: mohamed-moataz \\nMilitary Status: Completed. Professional Summary:  \\nData Scientist with a strong foundation in mathematics and experience in developing and deploying AI \\nmodels.')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_documents(\"What is my email addres?\" , 1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_with_rag_and_agent(query: str):\n",
    "    \"\"\"Process a query using RAG + agent.\"\"\"\n",
    "    print(f\"\\n--- Processing query with RAG + Agent: '{query}' ---\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    relevant_docs = search_documents(query, k=1)\n",
    "    context_text = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Enrich the query with context\n",
    "    enriched_query = (\n",
    "        f\"I have a question that may require information from these documents:\\n\\n\"\n",
    "        f\"{context_text}\\n\\n\"\n",
    "        f\"My question is: {query}\"\n",
    "    )\n",
    "    \n",
    "    # Process with the agent\n",
    "    print(\"\\nSending to agent with context...\")\n",
    "    response = agent.invoke(input=enriched_query)\n",
    "    \n",
    "    print(f\"\\nFinal response: {response['output']}\")\n",
    "    print(\"-----------------------------------\\n\")\n",
    "    \n",
    "    return response['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing query with RAG + Agent: 'What is my email addres?' ---\n",
      "\n",
      "--- Searching for: 'What is my email addres?' ---\n",
      "Found 1 relevant chunks:\n",
      "\n",
      "Result 1:\n",
      "Content: Mohamed Moataz \n",
      "Phone: (+20) 1120682864             \n",
      "Email:  mohamad.motaz.mostafa@gmail.com             \n",
      "LinkedIn: mohamed-moataz \n",
      "Military Status: Completed. Professional Summary:  \n",
      "Data Scientist with a strong foundation in mathematics and experience in developing and deploying AI \n",
      "models.\n",
      "Similarity: Present in top 1 results\n",
      "\n",
      "Sending to agent with context...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"mohamad.motaz.mostafa@gmail.com\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: mohamad.motaz.mostafa@gmail.com\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mohamad.motaz.mostafa@gmail.com'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_with_rag_and_agent(\"What is my email addres?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing query with RAG + Agent: 'what was my ranking in QTech hakathon?' ---\n",
      "\n",
      "--- Searching for: 'what was my ranking in QTech hakathon?' ---\n",
      "Found 1 relevant chunks:\n",
      "\n",
      "Result 1:\n",
      "Content: All certifications are available upon request. GitHub \n",
      "Hackathons: \n",
      "Q-tech & ITI Hackathon \n",
      "Ranked 3rd place among 15 different teams from ITI graduation projects. Certificate  \n",
      "Certifications\n",
      " Intermediate Machine Learning, Kaggle.\n",
      "Similarity: Present in top 1 results\n",
      "\n",
      "Sending to agent with context...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Ranked 3rd place among 15 different teams from ITI graduation projects.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: Ranked 3rd place among 15 different teams from ITI graduation projects.\n",
      "-----------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ranked 3rd place among 15 different teams from ITI graduation projects.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_with_rag_and_agent(\"what was my ranking in QTech hakathon?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
