{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    ".Yellow{color: Yellow;}\n",
    ".Black{color: Black;}\n",
    ".custom-style {\n",
    "    color: Maroon;\n",
    "    font-family: sans-serif;\n",
    "    font-size: 150px;\n",
    "    text-align: center;\n",
    "    margin-top: 5px;\n",
    "    margin-bottom: 5px;\n",
    "}\n",
    "</style>\n",
    "<p class=\"custom-style\">\n",
    "<span class=Black>De</span>\n",
    "<span class=Yellow>X</span>\n",
    "<span class=Black>alo</span>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this project, I will develop a simple RAG (Retrieval-Augmented Generation) powered by OpenAI model with LangChain. and a calculator tool.\n",
    "\n",
    "## `This Notebook is only to test the tools used in the project.`\n",
    "# Key Requirements\n",
    "- The application should be able to answer questions about the content of a PDF/txt file.\n",
    "- The application should be able to perform calculations using a calculator tool.\n",
    "- The application should be able to handle multiple files and provide answers based on the content of the files.\n",
    "- A FastAPI backend\n",
    "- A React frontend\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "Any necessary libraries are imported in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import Type\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definition & Global Variables\n",
    "The functions & global or enviroment variables that will be used in the notebook are defined in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple calculator tool that our agent can use\n",
    "class CalculatorInput(BaseModel):\n",
    "    expression: str = Field(description=\"Mathematical expression to evaluate\")\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name: str = \"calculator\"\n",
    "    description: str = \"Useful for performing mathematical calculations\"\n",
    "    args_schema: Type[BaseModel] = CalculatorInput\n",
    "    \n",
    "    def _run(self, expression: str) -> str:\n",
    "        \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "        try:\n",
    "            # Add basic math functions to the locals\n",
    "            local_dict = {\n",
    "                'sqrt': math.sqrt,\n",
    "                'pow': pow,\n",
    "                'abs': abs,\n",
    "                'round': round,\n",
    "                'max': max,\n",
    "                'min': min,\n",
    "                'sin': math.sin,\n",
    "                'cos': math.cos,\n",
    "                'tan': math.tan,\n",
    "                'pi': math.pi,\n",
    "                'e': math.e,\n",
    "                'log': math.log,\n",
    "                'log10': math.log10,\n",
    "                'floor': math.floor,\n",
    "                'ceil': math.ceil\n",
    "            }\n",
    "            \n",
    "            # Evaluate the expression\n",
    "            result = eval(expression, {\"__builtins__\": {}}, local_dict)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Error evaluating expression: {str(e)}\"\n",
    "\n",
    "    async def _arun(self, expression: str) -> str:\n",
    "        \"\"\"Async version of _run.\"\"\"\n",
    "        return self._run(expression)\n",
    "    \n",
    "\n",
    "\n",
    "def test_agent(query , agent):\n",
    "    print(f\"\\n--- Testing: '{query}' ---\")\n",
    "    response = agent.invoke(input=query)\n",
    "    print(f\"\\nFinal response: {response['output']}\")\n",
    "    print(\"-----------------------------------\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Define a simple function to simulate RAG context\n",
    "def query_with_context(query, context , agent):\n",
    "    \"\"\"Simulate a query with RAG context\"\"\"\n",
    "    enriched_query = (\n",
    "        f\"I have a question that may require information from these documents:\\n\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        f\"My question is: {query}\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Testing with RAG context ---\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Using context: '{context[:100]}...'\")\n",
    "    \n",
    "    response = agent.invoke(input=enriched_query)\n",
    "    \n",
    "    print(f\"\\nFinal response: {response['output']}\")\n",
    "    print(\"-----------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "This section demonstrates how LangChain agents work with tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\") # start by using the gpt-3.5-turbo model then switch to gpt-4 if needed or after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# test with simple prompt\n",
    "answer = llm.invoke(\"What is the capital of France?\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create memory to store chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CalculatorTool()]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,  # This shows the agent's thought process\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the agent with different types of queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing: 'What is the square root of 144 plus 5?' ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"calculator\",\n",
      "    \"action_input\": \"sqrt(144) + 5\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m17.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"17.0\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: 17.0\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_agent(\"What is the square root of 144 plus 5?\", agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing: 'Tell me about the weather today' ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I'm an AI assistant and do not have real-time information. You can check the weather using a weather website or app for the most up-to-date information.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: I'm an AI assistant and do not have real-time information. You can check the weather using a weather website or app for the most up-to-date information.\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_agent(\"Tell me about the weather today\" , agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing: 'If I have 3 apples and each costs $2.50, and I also buy 2 oranges at $1.75 each, how much will I spend in total?' ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"calculator\",\n",
      "    \"action_input\": \"3 * 2.50 + 2 * 1.75\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m11.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"11.0\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: 11.0\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_agent(\"If I have 3 apples and each costs $2.50, and I also buy 2 oranges at $1.75 each, how much will I spend in total?\" , agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with RAG context ---\n",
      "Query: 'What was my graduation project?'\n",
      "Using context: 'Projects: \n",
      " Wireless Chess Robotic Arm (WCRA-AI)  Graduation Project. Grade: Excellent.  \n",
      "▪ Designe...'\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Wireless Chess Robotic Arm (WCRA-AI) Graduation Project. Grade: Excellent. Designed & built a chess-playing robotic arm utilizing CNN and IoT with two operation modes. Implemented strategic decision-making using the NegaMax search algorithm on a Raspberry Pi. Guide search algorithm with efficiently updatable neural network (NNUE) as evaluation function. Integrated computer vision for gameplay & data collection to train CNN. Kaggle\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final response: Wireless Chess Robotic Arm (WCRA-AI) Graduation Project. Grade: Excellent. Designed & built a chess-playing robotic arm utilizing CNN and IoT with two operation modes. Implemented strategic decision-making using the NegaMax search algorithm on a Raspberry Pi. Guide search algorithm with efficiently updatable neural network (NNUE) as evaluation function. Integrated computer vision for gameplay & data collection to train CNN. Kaggle\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample context that simulates retrieved document chunks from my CV\n",
    "sample_context = \"\"\"Projects: \n",
    " Wireless Chess Robotic Arm (WCRA-AI)  Graduation Project. Grade: Excellent.  \n",
    "▪ Designed & built a chess-playing robotic arm utilizing CNN and IoT with two operation modes. \n",
    "▪ Implemented strategic decision-making using the NegaMax search algorithm on a Raspberry Pi. \n",
    "▪ Guide search algorithm with efficiently updatable neural network (NNUE) as evaluation function. \n",
    "▪ Integrated computer vision for gameplay & data collection to train CNN. Kaggle \n",
    " AI Model Testing & Reporting (NLP  Computer Vision) (Individual) \n",
    "▪ Extracted CAMeLBERT sentiment analysis strengths, drawbacks & potential use cases in a report. \n",
    "▪ Extracted FaceNet512 strengths & drawbacks through challenging selective examples in a report. \n",
    " Quantity Forecasting Across Different Products & Cities (Time Series) (Individual). \n",
    "▪ Data exploration, visualization, preprocessing & feature engineering. \n",
    "▪ Time series cross-validation Modeling (Exponential smoothing, ARIMA, Prophet, & LSTM). \n",
    "▪ Tailor a new zero-aware error metric to suit the problem & squeeze performance using N-BEATS. \n",
    " Enhanced Valuation of Personal Injury Claims (Omdena Project) Demo. \n",
    "▪ Collaborated with an international team to develop a predictive model for injury claims. \n",
    "▪ Data collection, analysis, visualization, and preprocessing. \n",
    "▪ Applied machine learning techniques to improve transparency and accuracy in legal processes. \n",
    " AI Research Assistant (CrewAI) (individual). \n",
    "▪ Multi-agent AI system to help researchers identify trends and research gaps. \n",
    "▪ 3 specialized AI agents to conduct comprehensive research & a user-friendly Streamlit app. \n",
    "▪ Utilize APIs to access the latest research papers and tech news to guide the next research steps. \n",
    "\"\"\"\n",
    "\n",
    "# Test with context\n",
    "query_with_context(\"What was my graduation project?\", sample_context , agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
